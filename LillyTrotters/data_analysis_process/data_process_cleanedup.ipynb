{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "file_locs = \"../datacrawl/crawled_data/*/*.json\"\n",
    "import json\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"The file {file_path} was not found\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise json.JSONDecodeError(f\"Error parsing JSON file: {str(e)}\", e.doc, e.pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = read_json_file('../datacrawl/crawled_data/61723086/data.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"configuration\": {\n",
      "    \"actTimeout\": \"int\",\n",
      "    \"env_cfg\": {\n",
      "      \"map_height\": \"int\",\n",
      "      \"map_width\": \"int\",\n",
      "      \"match_count_per_episode\": \"int\",\n",
      "      \"max_steps_in_match\": \"int\",\n",
      "      \"max_units\": \"int\",\n",
      "      \"num_teams\": \"int\",\n",
      "      \"unit_move_cost\": \"int\",\n",
      "      \"unit_sap_cost\": \"int\",\n",
      "      \"unit_sap_range\": \"int\",\n",
      "      \"unit_sensor_range\": \"int\",\n",
      "    },\n",
      "    \"episodeSteps\": \"int\",\n",
      "    \"runTimeout\": \"int\",\n",
      "    \"seed\": \"int\",\n",
      "  },\n",
      "  \"description\": \"str\",\n",
      "  \"id\": \"str\",\n",
      "  \"info\": {\n",
      "    \"EpisodeId\": \"int\",\n",
      "    \"LiveVideoPath\": \"NoneType\",\n",
      "    \"TeamNames\": [\"str\"],\n",
      "  },\n",
      "  \"name\": \"str\",\n",
      "  \"rewards\": [\"int\"],\n",
      "  \"schema_version\": \"int\",\n",
      "  \"specification\": {\n",
      "    \"action\": {\n",
      "      \"default\": \"int\",\n",
      "      \"description\": \"str\",\n",
      "      \"type\": \"str\",\n",
      "    },\n",
      "    \"agents\": [\"int\"],\n",
      "    \"configuration\": {\n",
      "      \"actTimeout\": {\n",
      "        \"default\": \"int\",\n",
      "        \"description\": \"str\",\n",
      "        \"minimum\": \"int\",\n",
      "        \"type\": \"str\",\n",
      "      },\n",
      "      \"env_cfg\": {\n",
      "        \"description\": \"str\",\n",
      "        \"type\": \"str\",\n",
      "      },\n",
      "      \"episodeSteps\": {\n",
      "        \"default\": \"int\",\n",
      "        \"description\": \"str\",\n",
      "        \"minimum\": \"int\",\n",
      "        \"type\": \"str\",\n",
      "      },\n",
      "      \"runTimeout\": {\n",
      "        \"default\": \"int\",\n",
      "        \"description\": \"str\",\n",
      "        \"minimum\": \"int\",\n",
      "        \"type\": \"str\",\n",
      "      },\n",
      "      \"seed\": {\n",
      "        \"description\": \"str\",\n",
      "        \"type\": \"str\",\n",
      "      },\n",
      "    },\n",
      "    \"info\": {\n",
      "    },\n",
      "    \"observation\": {\n",
      "      \"obs\": {\n",
      "        \"description\": \"str\",\n",
      "        \"shared\": \"bool\",\n",
      "        \"type\": \"str\",\n",
      "      },\n",
      "      \"player\": {\n",
      "        \"defaults\": \"str\",\n",
      "        \"description\": \"str\",\n",
      "        \"type\": \"str\",\n",
      "      },\n",
      "      \"remainingOverageTime\": {\n",
      "        \"default\": \"int\",\n",
      "        \"description\": \"str\",\n",
      "        \"minimum\": \"int\",\n",
      "        \"shared\": \"bool\",\n",
      "        \"type\": \"str\",\n",
      "      },\n",
      "      \"reward\": {\n",
      "        \"default\": \"int\",\n",
      "        \"description\": \"str\",\n",
      "        \"type\": \"str\",\n",
      "      },\n",
      "      \"step\": {\n",
      "        \"default\": \"int\",\n",
      "        \"description\": \"str\",\n",
      "        \"minimum\": \"int\",\n",
      "        \"shared\": \"bool\",\n",
      "        \"type\": \"str\",\n",
      "      },\n",
      "    },\n",
      "    \"reward\": {\n",
      "      \"default\": \"int\",\n",
      "      \"description\": \"str\",\n",
      "      \"type\": [\"str\"],\n",
      "    },\n",
      "  },\n",
      "  \"statuses\": [\"str\"],\n",
      "  \"steps\": [[{\n",
      "    \"action\": {\n",
      "    },\n",
      "    \"info\": {\n",
      "      \"replay\": {\n",
      "        \"metadata\": {\n",
      "          \"seed\": \"int\",\n",
      "        },\n",
      "        \"observations\": [{\n",
      "          \"energy_nodes\": [[\"int\"]],\n",
      "          \"map_features\": {\n",
      "            \"energy\": [[\"int\"]],\n",
      "            \"tile_type\": [[\"int\"]],\n",
      "          },\n",
      "          \"match_steps\": \"int\",\n",
      "          \"relic_node_configs\": [[[\"bool\"]]],\n",
      "          \"relic_nodes\": [[\"int\"]],\n",
      "          \"steps\": \"int\",\n",
      "          \"team_points\": [\"int\"],\n",
      "          \"team_wins\": [\"int\"],\n",
      "          \"units\": {\n",
      "            \"energy\": [[[\"int\"]]],\n",
      "            \"position\": [[[\"int\"]]],\n",
      "          },\n",
      "          \"units_mask\": [[\"bool\"]],\n",
      "          \"vision_power_map\": [[[\"int\"]]],\n",
      "        }],\n",
      "        \"params\": {\n",
      "          \"energy_node_drift_magnitude\": \"int\",\n",
      "          \"energy_node_drift_speed\": \"float\",\n",
      "          \"fog_of_war\": \"bool\",\n",
      "          \"init_unit_energy\": \"int\",\n",
      "          \"map_height\": \"int\",\n",
      "          \"map_type\": \"int\",\n",
      "          \"map_width\": \"int\",\n",
      "          \"match_count_per_episode\": \"int\",\n",
      "          \"max_energy_nodes\": \"int\",\n",
      "          \"max_energy_per_tile\": \"int\",\n",
      "          \"max_relic_nodes\": \"int\",\n",
      "          \"max_steps_in_match\": \"int\",\n",
      "          \"max_unit_energy\": \"int\",\n",
      "          \"max_units\": \"int\",\n",
      "          \"min_energy_per_tile\": \"int\",\n",
      "          \"min_unit_energy\": \"int\",\n",
      "          \"nebula_tile_drift_speed\": \"float\",\n",
      "          \"nebula_tile_energy_reduction\": \"int\",\n",
      "          \"nebula_tile_vision_reduction\": \"int\",\n",
      "          \"num_teams\": \"int\",\n",
      "          \"relic_config_size\": \"int\",\n",
      "          \"spawn_rate\": \"int\",\n",
      "          \"unit_energy_void_factor\": \"float\",\n",
      "          \"unit_move_cost\": \"int\",\n",
      "          \"unit_sap_cost\": \"int\",\n",
      "          \"unit_sap_dropoff_factor\": \"float\",\n",
      "          \"unit_sap_range\": \"int\",\n",
      "          \"unit_sensor_range\": \"int\",\n",
      "        },\n",
      "      },\n",
      "    },\n",
      "    \"observation\": {\n",
      "      \"obs\": \"str\",\n",
      "      \"player\": \"str\",\n",
      "      \"remainingOverageTime\": \"int\",\n",
      "      \"reward\": \"int\",\n",
      "      \"step\": \"int\",\n",
      "    },\n",
      "    \"reward\": \"int\",\n",
      "    \"status\": \"str\",\n",
      "  }]],\n",
      "  \"title\": \"str\",\n",
      "  \"version\": \"str\",\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def get_json_schema(data):\n",
    "    \"\"\"\n",
    "    Extract schema from JSON data\n",
    "    Returns a dict representing the structure, with types as values\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {\n",
    "            key: get_json_schema(value)\n",
    "            for key, value in data.items()\n",
    "        }\n",
    "    elif isinstance(data, list):\n",
    "        # If list is empty, return empty list schema\n",
    "        if not data:\n",
    "            return [\"array (empty)\"]\n",
    "        # If all items are same type, just return first item's schema\n",
    "        if all(isinstance(x, type(data[0])) for x in data):\n",
    "            return [get_json_schema(data[0])]\n",
    "        # If mixed types, return schema for each unique type\n",
    "        return [get_json_schema(x) for x in data]\n",
    "    else:\n",
    "        return type(data).__name__\n",
    "\n",
    "def print_schema(schema, indent=0):\n",
    "    \"\"\"Pretty print the schema\"\"\"\n",
    "    if isinstance(schema, dict):\n",
    "        result = \"{\\n\"\n",
    "        for key, value in schema.items():\n",
    "            result += \" \" * (indent + 2) + f'\"{key}\": '\n",
    "            result += print_schema(value, indent + 2)\n",
    "            result += \",\\n\"\n",
    "        result += \" \" * indent + \"}\"\n",
    "        return result\n",
    "    elif isinstance(schema, list):\n",
    "        if len(schema) == 1:\n",
    "            return f\"[{print_schema(schema[0], indent)}]\"\n",
    "        else:\n",
    "            result = \"[\\n\"\n",
    "            for item in schema:\n",
    "                result += \" \" * (indent + 2)\n",
    "                result += print_schema(item, indent + 2)\n",
    "                result += \",\\n\"\n",
    "            result += \" \" * indent + \"]\"\n",
    "            return result\n",
    "    else:\n",
    "        return f'\"{schema}\"'\n",
    "\n",
    "\n",
    "\n",
    "schema = get_json_schema(data_1)\n",
    "print(print_schema(schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def process_observation(replay_observation):\n",
    "    \"\"\"Convert replay observation into tensor format\"\"\"\n",
    "    return {\n",
    "        'map_features': {\n",
    "            'energy': torch.FloatTensor(replay_observation['map_features']['energy']),\n",
    "            'tile_type': torch.FloatTensor(replay_observation['map_features']['tile_type'])\n",
    "        },\n",
    "        'sensor_mask': torch.FloatTensor(replay_observation['sensor_mask']),\n",
    "        'units': {\n",
    "            'position': torch.FloatTensor(replay_observation['units']['position']),\n",
    "            'energy': torch.FloatTensor(replay_observation['units']['energy'])\n",
    "        },\n",
    "        'units_mask': torch.FloatTensor(replay_observation['units_mask']),\n",
    "        'relic_nodes': torch.FloatTensor(replay_observation['relic_nodes']),\n",
    "        'energy_nodes': torch.FloatTensor(replay_observation['energy_nodes'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "@dataclass\n",
    "class GameStats:\n",
    "    round_won: bool\n",
    "    relic_points: int\n",
    "    total_energy: int\n",
    "    relic_tiles_found: float\n",
    "    area_explored: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def network_to_env_actions(network_outputs, num_units=16):\n",
    "    \"\"\"\n",
    "    Convert network outputs back to environment action format\n",
    "    \n",
    "    Args:\n",
    "        network_outputs: Dictionary containing network outputs\n",
    "            - action_probs: Action type probabilities\n",
    "            - unit_probs: Unit selection probabilities\n",
    "            - offset_x: X coordinate offsets\n",
    "            - offset_y: Y coordinate offsets\n",
    "        num_units: Number of units in the environment\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of shape (N, 3) containing environment actions\n",
    "    \"\"\"\n",
    "    # Initialize empty action array\n",
    "    env_actions = np.zeros((num_units, 3), dtype=int)\n",
    "    \n",
    "    # Get selected actions and units\n",
    "    actions = torch.argmax(network_outputs['action_probs'], dim=1)\n",
    "    units = torch.argmax(network_outputs['unit_probs'], dim=1)\n",
    "    \n",
    "    # Get coordinate offsets\n",
    "    offset_x = network_outputs['offset_x'].detach().numpy()\n",
    "    offset_y = network_outputs['offset_y'].detach().numpy()\n",
    "    \n",
    "    for i, (action, unit) in enumerate(zip(actions, units)):\n",
    "        if action == 0:  # Move action\n",
    "            # Convert offset to cardinal direction\n",
    "            dx = offset_x[i]\n",
    "            dy = offset_y[i]\n",
    "            \n",
    "            # Convert to closest cardinal direction\n",
    "            if abs(dx) > abs(dy):\n",
    "                if dx > 0:\n",
    "                    action_type = 2  # Right\n",
    "                else:\n",
    "                    action_type = 4  # Left\n",
    "            else:\n",
    "                if dy > 0:\n",
    "                    action_type = 3  # Down\n",
    "                else:\n",
    "                    action_type = 1  # Up\n",
    "                    \n",
    "            env_actions[unit] = [action_type, 0, 0]\n",
    "            \n",
    "        elif action == 1:  # Sap action\n",
    "            dx = round(offset_x[i])\n",
    "            dy = round(offset_y[i])\n",
    "            env_actions[unit] = [5, dx, dy]\n",
    "    \n",
    "    return env_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def parse_observation(obs):\n",
    "    \"\"\"\n",
    "    Convert raw observation dict into tensor format required by LuxAIObservationEncoder\n",
    "    \n",
    "    Args:\n",
    "        raw_obs (dict): Raw observation dictionary from the environment\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processed observation with tensors\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\n",
    "        'map_features': {\n",
    "            'energy': torch.FloatTensor(obs['map_features']['energy']).unsqueeze(0),\n",
    "            'tile_type': torch.FloatTensor(obs['map_features']['tile_type']).unsqueeze(0)\n",
    "        },\n",
    "        'sensor_mask': torch.FloatTensor(obs['sensor_mask']).unsqueeze(0),\n",
    "        'units': {\n",
    "            'position': torch.FloatTensor(obs['units']['position']).unsqueeze(0),\n",
    "            'energy': torch.FloatTensor(obs['units']['energy']).unsqueeze(0)\n",
    "        },\n",
    "        'units_mask': torch.FloatTensor(obs['units_mask']).unsqueeze(0),\n",
    "        'relic_nodes': torch.FloatTensor(obs['relic_nodes']).unsqueeze(0),\n",
    "        'relic_nodes_mask': torch.FloatTensor(obs['relic_nodes_mask']).unsqueeze(0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Player 0:\n",
      "{'map_features': {'energy': tensor([[[ 0.,  2.,  4.,  5.,  6.,  7.,  7.,  7.,  7.,  7., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [ 5.,  7.,  7.,  7.,  6.,  6.,  6.,  6.,  6.,  7., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [ 7.,  5.,  3., -1., -1., -1., -1., -2., -1.,  0., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [ 2., -1., -1., -1., -1., -5., -5., -5., -6., -6., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]]]), 'tile_type': tensor([[[ 0.,  0.,  0.,  0.,  2.,  2.,  0.,  0.,  0.,  0., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0., -1., -1.,  0.,  0.,  0.,  0.,  0., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [ 0.,  0., -1., -1., -1.,  0.,  0.,  0.,  0.,  0., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]]])}, 'sensor_mask': tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]]]), 'units': {'position': tensor([[[[ 1.,  7.],\n",
      "          [ 1.,  4.],\n",
      "          [ 1.,  1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.]],\n",
      "\n",
      "         [[-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.]]]]), 'energy': tensor([[[126., 117., 106.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
      "           -1.,  -1.,  -1.,  -1.,  -1.],\n",
      "         [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
      "           -1.,  -1.,  -1.,  -1.,  -1.]]])}, 'units_mask': tensor([[[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]), 'relic_nodes': tensor([[[-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.]]]), 'relic_nodes_mask': tensor([[0., 0., 0., 0., 0., 0.]])}\n",
      "GameStats(round_won=0, relic_points=0, total_energy=349, relic_tiles_found=0.0, area_explored=0.06076388888888889)\n",
      "\n",
      "Player 1:\n",
      "{'map_features': {'energy': tensor([[[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -6.,  0.,  7.,  7.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -6., -1.,  6.,  7.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -5., -2.,  6.,  7.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -5., -1.,  6.,  7.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -5., -1.,  6.,  7.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1.,  6.,  6.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1.,  7.,  5.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1.,  3.,  7.,  4.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1.,  5.,  7.,  2.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1.,  2.,  7.,  5.,  0.]]]), 'tile_type': tensor([[[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1.,  0.,  0.,  0.,  0.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1.,  0.,  0.,  0.,  0.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1.,  0.,  0.,  0.,  0.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1.,  0.,  0.,  0.,  0.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1.,  0.,  0.,  0.,  2.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1.,  0.,  2.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1., -1.,  0.,  0.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1., -1.,  0.,  0.,  0.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1.,  0.,  0.,  0.,  0.],\n",
      "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "          -1., -1., -1., -1., -1., -1.,  0.,  0.,  0.,  0.]]])}, 'sensor_mask': tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 1., 1., 1.]]]), 'units': {'position': tensor([[[[-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.]],\n",
      "\n",
      "         [[16., 22.],\n",
      "          [19., 22.],\n",
      "          [22., 22.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.],\n",
      "          [-1., -1.]]]]), 'energy': tensor([[[ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
      "           -1.,  -1.,  -1.,  -1.,  -1.],\n",
      "         [126., 117., 106.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
      "           -1.,  -1.,  -1.,  -1.,  -1.]]])}, 'units_mask': tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]), 'relic_nodes': tensor([[[-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.]]]), 'relic_nodes_mask': tensor([[0., 0., 0., 0., 0., 0.]])}\n",
      "GameStats(round_won=1, relic_points=0, total_energy=349, relic_tiles_found=0.0, area_explored=0.06076388888888889)\n"
     ]
    }
   ],
   "source": [
    "step = data_1[\"steps\"][110]\n",
    "\n",
    "for i, each_player in enumerate(step):\n",
    "    obs = each_player[\"observation\"][\"obs\"]\n",
    "    obs = json.loads(obs)\n",
    "    print(f\"\\nPlayer {i}:\")\n",
    "    print(parse_observation(obs))\n",
    "    \n",
    "    total_energy = obs['units']['energy'][i]\n",
    "    total_energy = sum(num for num in total_energy if num != -1)\n",
    "    \n",
    "    \n",
    "    print(GameStats(\n",
    "        round_won=obs['team_wins'][i] ,\n",
    "        relic_points=obs['team_points'][i],\n",
    "        total_energy=total_energy,\n",
    "        relic_tiles_found=np.mean(obs['relic_nodes_mask']),\n",
    "        area_explored=np.mean(obs['sensor_mask'])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def env_to_network_actions(env_actions):\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert environment actions to network format\n",
    "    \n",
    "    Args:\n",
    "        env_actions: List/array of shape (N, 3) where each action is [action_type, dx, dy]\n",
    "                    action_type: 0=nothing, 1=up, 2=right, 3=down, 4=left, 5=sap\n",
    "    \n",
    "    Returns:\n",
    "        dict containing:\n",
    "            actions_taken: Tensor of action indices\n",
    "            units_selected: Tensor of unit indices for active units\n",
    "            coords_taken: Tensor of coordinate offsets\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Convert to numpy if not already\n",
    "    \n",
    "    # Find active units (where action_type != 0)\n",
    "    if  len(env_actions)==0:  # This checks if list is empty\n",
    "        return {\n",
    "        'actions_taken': torch.tensor([[0]]),  # No-op action\n",
    "        'units_selected': torch.tensor([[0]]),  # First unit\n",
    "        'coords_taken': torch.zeros(1, 2)  # No movement\n",
    "        }\n",
    "    env_actions = np.array(env_actions)\n",
    "    active_units = np.where(env_actions[:, 0] != 0)[0]\n",
    "    \n",
    "    if len(active_units) == 0:\n",
    "        # Handle case where no actions are taken\n",
    "        return {\n",
    "            'actions_taken': torch.tensor([[0]]),  # No-op action\n",
    "            'units_selected': torch.tensor([[0]]),  # First unit\n",
    "            'coords_taken': torch.zeros(1, 2)  # No movement\n",
    "        }\n",
    "    \n",
    "    # For each active unit, convert their action\n",
    "    action_indices = []\n",
    "    coord_offsets = []\n",
    "    \n",
    "    for unit_idx in active_units:\n",
    "        action = env_actions[unit_idx]\n",
    "        action_type = action[0]\n",
    "        \n",
    "        if action_type == 5:  # Sap action\n",
    "            action_idx = 2  # Assuming 1 represents \"Zap\" in your network\n",
    "            dx, dy = action[1], action[2]\n",
    "        else:  # Movement actions\n",
    "            action_idx = 1  #  0 represents \"Move\"\n",
    "            # Convert cardinal directions to dx, dy\n",
    "            if action_type == 1:    # Up\n",
    "                dx, dy = 0, -1\n",
    "            elif action_type == 2:  # Right\n",
    "                dx, dy = 1, 0\n",
    "            elif action_type == 3:  # Down\n",
    "                dx, dy = 0, 1\n",
    "            elif action_type == 4:  # Left\n",
    "                dx, dy = -1, 0\n",
    "                \n",
    "        action_indices.append(action_idx)\n",
    "        coord_offsets.append([dx, dy])\n",
    "    \n",
    "    # Convert to tensors\n",
    "    actions_taken = torch.tensor(action_indices).view(-1, 1)\n",
    "    units_selected = torch.tensor(active_units).view(-1, 1)\n",
    "    coords_taken = torch.tensor(coord_offsets, dtype=torch.float)\n",
    "    \n",
    "    return {\n",
    "        'actions_taken': actions_taken,\n",
    "        'units_selected': units_selected,\n",
    "        'coords_taken': coords_taken\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network format:\n",
      "actions_taken:\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]])\n",
      "\n",
      "units_selected:\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2]])\n",
      "\n",
      "coords_taken:\n",
      "tensor([[-1.,  0.],\n",
      "        [-1.,  0.],\n",
      "        [-1.,  0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action = each_player[\"action\"]\n",
    "# Example environment actions\n",
    "env_actions = action\n",
    "\n",
    "# Convert to network format\n",
    "network_actions = env_to_network_actions(action)\n",
    "\n",
    "print(\"Network format:\")\n",
    "for k, v in network_actions.items():\n",
    "    print(f\"{k}:\\n{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuxGameParser:\n",
    "    def __init__(self, map_size=24, max_units=16):\n",
    "        self.map_size = map_size\n",
    "        self.max_units = max_units\n",
    "    \n",
    "    def parse_game_file(self, file_path: str) -> List[GameStats]:\n",
    "        with open(file_path, 'r') as f:\n",
    "            game_data = json.load(f)\n",
    "        env_stats = [[],[]]\n",
    "        actions_stats  = [[],[]]\n",
    "        game_stats = [[],[]]\n",
    "        for step in game_data['steps']:\n",
    "            for i, each_player in enumerate(step):\n",
    "                obs = each_player[\"observation\"][\"obs\"]\n",
    "                obs = json.loads(obs)\n",
    "                env_stats[i].append(parse_observation(obs))\n",
    "                \n",
    "                env_actions = each_player[\"action\"]\n",
    "                network_actions = env_to_network_actions(env_actions)\n",
    "                \n",
    "                total_energy = obs['units']['energy'][i]\n",
    "                total_energy = sum(num for num in total_energy if num != -1)\n",
    "                \n",
    "                actions_stats[i].append(network_actions)\n",
    "                game_stats[i].append(GameStats(\n",
    "                    round_won=obs['team_wins'][i] ,\n",
    "                    relic_points=obs['team_points'][i],\n",
    "                    total_energy=total_energy,\n",
    "                    relic_tiles_found=np.mean(obs['relic_nodes_mask']),\n",
    "                    area_explored=np.mean(obs['sensor_mask'])\n",
    "                ))\n",
    "                \n",
    "        return env_stats, game_stats,actions_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "luxParse = LuxGameParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 333 ms, sys: 65.5 ms, total: 399 ms\n",
      "Wall time: 398 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "env_stats, game_stats, actions_stats = luxParse.parse_game_file( glob(file_locs)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 16, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_stats[0][1][\"units\"][\"position\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actions_stats[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SpatialEncoder(nn.Module):\n",
    "    def __init__(self, width=24, height=24):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),  # 3 channels: energy, tile_type, sensor_mask\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Linear(64 * (width//2) * (height//2), 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x.view(x.size(0), -1))\n",
    "\n",
    "class UnitProcessor(nn.Module):\n",
    "    def __init__(self, max_units=16):\n",
    "        super().__init__()\n",
    "        self.max_units = max_units\n",
    "        self.fc1 = nn.Linear(3, 64)  # position (2) + energy (1)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        \n",
    "    def forward(self, positions, energy, mask):\n",
    "        # Reshape it to add it in  the last deminsion\n",
    "        energy = energy.unsqueeze(-1) \n",
    "        # Combine position and energy\n",
    "        features = torch.cat([positions, energy], dim=-1)  # Shape: (batch, teams, units, 3)\n",
    "        \n",
    "        # Process each unit\n",
    "        x = torch.relu(self.fc1(features))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        \n",
    "        # Apply mask\n",
    "        x = x * mask.unsqueeze(-1)\n",
    "        \n",
    "        # Pool over units dimension\n",
    "        return torch.max(x, dim=2)[0]  # Shape: (batch, teams, 128)\n",
    "\n",
    "class RelicProcessor(nn.Module):\n",
    "    def __init__(self, max_relics=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)  # position only\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        \n",
    "    def forward(self, positions, mask):\n",
    "        x = torch.relu(self.fc1(positions))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        \n",
    "        # Apply mask\n",
    "        x = x * mask.unsqueeze(-1)\n",
    "        \n",
    "        # Pool over relics\n",
    "        return torch.max(x, dim=1)[0]\n",
    "\n",
    "class LuxAIObservationEncoder(nn.Module):\n",
    "    def __init__(self, width=24, height=24, max_units=10, max_relics=10,final_dim=512):\n",
    "        super().__init__()\n",
    "        self.spatial_encoder = SpatialEncoder(width, height)\n",
    "        self.unit_processor = UnitProcessor(max_units)\n",
    "        self.relic_processor = RelicProcessor(max_relics)\n",
    "\n",
    "        # Calculate total embedding dimension\n",
    "        spatial_dim = 256\n",
    "        units_dim = 128 * 2  # For 2 teams\n",
    "        relic_dim = 128\n",
    "        total_dim = spatial_dim + units_dim + relic_dim\n",
    "        \n",
    "        self.output_layer = nn.Linear(total_dim, final_dim)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # Process spatial features\n",
    "        spatial_features = torch.cat([\n",
    "            obs['map_features']['energy'].unsqueeze(1),\n",
    "            obs['map_features']['tile_type'].unsqueeze(1),\n",
    "            obs['sensor_mask'].unsqueeze(1)\n",
    "        ], dim=1)\n",
    "        spatial_embed = self.spatial_encoder(spatial_features)\n",
    "\n",
    "        # Process units\n",
    "        unit_embed = self.unit_processor(\n",
    "            obs['units']['position'],\n",
    "            obs['units']['energy'],\n",
    "            obs['units_mask']\n",
    "        )\n",
    "        unit_embed = unit_embed.reshape(unit_embed.size(0), -1)  # Flatten teams dimension\n",
    "\n",
    "        # Process relics\n",
    "        relic_embed = self.relic_processor(\n",
    "            obs['relic_nodes'],\n",
    "            obs['relic_nodes_mask']\n",
    "        )\n",
    "\n",
    "        # Combine all embeddings\n",
    "        combined = torch.cat([\n",
    "            spatial_embed,\n",
    "            unit_embed,\n",
    "            relic_embed\n",
    "        ], dim=1)\n",
    "\n",
    "        return self.output_layer(combined)\n",
    "\n",
    "class GameStateProcessor:\n",
    "    def process_observation(self, obs):\n",
    "        \"\"\"Convert raw observation dict into tensor format\"\"\"\n",
    "        return {\n",
    "            'map_features': {\n",
    "                'energy': torch.FloatTensor(obs['obs']['map_features']['energy']),\n",
    "                'tile_type': torch.FloatTensor(obs['obs']['map_features']['tile_type'])\n",
    "            },\n",
    "            'sensor_mask': torch.FloatTensor(obs['obs']['sensor_mask']),\n",
    "            'units': {\n",
    "                'position': torch.FloatTensor(obs['obs']['units']['position']),\n",
    "                'energy': torch.FloatTensor(obs['obs']['units']['energy'])\n",
    "            },\n",
    "            'units_mask': torch.FloatTensor(obs['obs']['units_mask']),\n",
    "            'relic_nodes': torch.FloatTensor(obs['obs']['relic_nodes']),\n",
    "            'relic_nodes_mask': torch.FloatTensor(obs['obs']['relic_nodes_mask'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SequentialLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        \"\"\"\n",
    "        Initialize the LSTM model that processes sequences of observations.\n",
    "        \n",
    "        Args:\n",
    "            input_size (int): Size of each input observation\n",
    "            hidden_size (int): Number of features in the hidden state\n",
    "            output_size (int): Size of output action space\n",
    "            num_layers (int): Number of LSTM layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Main LSTM layer to process sequences\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            batch_first=True  # Use (batch, seq, feature) format\n",
    "        )\n",
    "        \n",
    "        # Linear layer to project LSTM output to action logits\n",
    "        self.action_head = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Initialize hidden state and cell state\n",
    "        self.hidden = None\n",
    "        self.cell = None\n",
    "        \n",
    "    def reset_states(self, batch_size=1, device='cuda'):\n",
    "        \"\"\"Reset the hidden and cell states\"\"\"\n",
    "        self.hidden = torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "        self.cell = torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, input_size)\n",
    "                            where seq_len=500 in your case\n",
    "        Returns:\n",
    "            outputs (torch.Tensor): Action logits for each timestep\n",
    "        \"\"\"\n",
    "        # Process the sequence through LSTM\n",
    "        lstm_out, (self.hidden, self.cell) = self.lstm(x, (self.hidden, self.cell))\n",
    "        \n",
    "        # Project LSTM outputs to action space for each timestep\n",
    "        action_logits = self.action_head(lstm_out)\n",
    "        \n",
    "        return action_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LuxAIObservationEncoder()\n",
    "obs = env_stats[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map_features': {'energy': tensor([[[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]]]),\n",
       "  'tile_type': tensor([[[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]]])},\n",
       " 'sensor_mask': tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]]]),\n",
       " 'units': {'position': tensor([[[[-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.]],\n",
       "  \n",
       "           [[-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.]]]]),\n",
       "  'energy': tensor([[[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1.]]])},\n",
       " 'units_mask': tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]),\n",
       " 'relic_nodes': tensor([[[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.]]]),\n",
       " 'relic_nodes_mask': tensor([[0., 0., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(obs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_features = torch.cat([\n",
    "            obs['map_features']['energy'].unsqueeze(1),\n",
    "            obs['map_features']['tile_type'].unsqueeze(1),\n",
    "            obs['sensor_mask'].unsqueeze(1)\n",
    "        ], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "         [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters in base network: 788480\n",
      "Parameters in policy network: 1069088\n",
      "Parameters in value network: 821505\n",
      "\n",
      "Behavior Cloning Losses:\n",
      "Total loss: 3.7338\n",
      "Action loss: 1.8542\n",
      "Unit loss: 0.8929\n",
      "Coordinate loss: 0.9867\n",
      "\n",
      "Network Outputs:\n",
      "Action probs shape: torch.Size([16, 16, 2])\n",
      "Unit probs shape: torch.Size([16, 16])\n",
      "Coordinates shape: torch.Size([16, 16, 2])\n",
      "\n",
      "Sampled Actions:\n",
      "Number of units selected: 128\n",
      "Actions shape: torch.Size([128, 1])\n",
      "Coordinates shape: torch.Size([128, 2])\n",
      "\n",
      "State values shape: torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaseNetwork(nn.Module):\n",
    "    \"\"\"Shared base network for processing state input\"\"\"\n",
    "    def __init__(self, lstm_hidden_size=256, embedding_dim=512):\n",
    "        super(BaseNetwork, self).__init__()\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # LSTM for processing state\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"\n",
    "        Process state through LSTM\n",
    "        Args:\n",
    "            state: Input state tensor (batch_size, seq_len, input_dim)\n",
    "        Returns:\n",
    "            lstm_final: Final LSTM hidden state (batch_size, lstm_hidden_size)\n",
    "        \"\"\"\n",
    "        lstm_out, _ = self.lstm(state)  # [batch_size, seq_len, lstm_hidden_size]\n",
    "        lstm_final = lstm_out[:, -1, :]  # [batch_size, lstm_hidden_size]\n",
    "        return lstm_final\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"Policy network for action selection\"\"\"\n",
    "    def __init__(self, base_network, action_dim=2, unit_dim=16):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.base = base_network\n",
    "        self.action_dim = action_dim\n",
    "        self.unit_dim = unit_dim\n",
    "        \n",
    "        # Action ID path\n",
    "        self.action_embedding = nn.Embedding(action_dim, base_network.embedding_dim)\n",
    "        self.action_fc = nn.Linear(base_network.lstm_hidden_size, base_network.embedding_dim)\n",
    "        \n",
    "        # Target unit path\n",
    "        self.unit_embedding = nn.Embedding(self.unit_dim, base_network.embedding_dim)\n",
    "        self.unit_fc = nn.Linear(base_network.lstm_hidden_size, base_network.embedding_dim)\n",
    "        \n",
    "        # Coordinate prediction\n",
    "        self.coord_fc = nn.Linear(base_network.lstm_hidden_size, self.unit_dim * 2)\n",
    "\n",
    "    def forward(self, state, available_actions, available_units):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state: Input state tensor (batch_size, seq_len, input_dim)\n",
    "            available_actions: Boolean mask of available actions (batch_size, action_dim)\n",
    "            available_units: Boolean mask of available units (batch_size, unit_dim)\n",
    "        Returns:\n",
    "            Dictionary containing action distributions for each unit\n",
    "        \"\"\"\n",
    "        lstm_final = self.base(state)\n",
    "        \n",
    "        # Target unit selection - now returns probabilities for EACH unit\n",
    "        unit_embeds = self.unit_embedding(torch.arange(self.unit_dim).to(state.device))\n",
    "        unit_query = self.unit_fc(lstm_final)\n",
    "        unit_scores = torch.matmul(unit_query, unit_embeds.t())\n",
    "        unit_scores = unit_scores.masked_fill(~available_units, float('-inf'))\n",
    "        # Instead of softmax, use sigmoid to allow multiple units to be selected\n",
    "        unit_probs = torch.sigmoid(unit_scores)\n",
    "        \n",
    "        # Action ID selection for each available unit\n",
    "        action_embeds = self.action_embedding(torch.arange(self.action_dim).to(state.device))\n",
    "        action_query = self.action_fc(lstm_final)\n",
    "        action_scores = torch.matmul(action_query, action_embeds.t())\n",
    "        action_scores = action_scores.masked_fill(~available_actions, float('-inf'))\n",
    "        \n",
    "        # Get action probabilities for each unit\n",
    "        action_probs = F.softmax(action_scores.unsqueeze(1).expand(-1, self.unit_dim, -1), dim=-1)\n",
    "        \n",
    "        # Coordinate prediction for each unit\n",
    "        coords_all = self.coord_fc(lstm_final)\n",
    "        coordinates = coords_all.view(-1, self.unit_dim, 2)\n",
    "        \n",
    "        return {\n",
    "            'action_probs': action_probs,  # [batch_size, unit_dim, action_dim]\n",
    "            'unit_probs': unit_probs,      # [batch_size, unit_dim]\n",
    "            'coordinates': coordinates,     # [batch_size, unit_dim, 2]\n",
    "        }\n",
    "\n",
    "    def sample_actions(self, outputs):\n",
    "        \"\"\"Sample actions for each selected unit\"\"\"\n",
    "        unit_mask = (outputs['unit_probs'] > 0.5)  # Binary selection of units\n",
    "        \n",
    "        if self.training:\n",
    "            actions = torch.multinomial(outputs['action_probs'][unit_mask], 1)\n",
    "        else:\n",
    "            actions = torch.argmax(outputs['action_probs'][unit_mask], dim=-1, keepdim=True)\n",
    "        \n",
    "        return {\n",
    "            'selected_units': unit_mask,\n",
    "            'actions': actions,\n",
    "            'coordinates': outputs['coordinates'][unit_mask]\n",
    "        }\n",
    "        \n",
    "class ValueNetwork(nn.Module):\n",
    "    \"\"\"Value network for state value estimation\"\"\"\n",
    "    def __init__(self, base_network):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.base = base_network\n",
    "        \n",
    "        # Value head\n",
    "        self.value_fc1 = nn.Linear(base_network.lstm_hidden_size, 128)\n",
    "        self.value_fc2 = nn.Linear(128, 1)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state: Input state tensor (batch_size, seq_len, input_dim)\n",
    "        Returns:\n",
    "            value: Predicted state value (batch_size, 1)\n",
    "        \"\"\"\n",
    "        lstm_final = self.base(state)\n",
    "        hidden = F.relu(self.value_fc1(lstm_final))\n",
    "        value = self.value_fc2(hidden)\n",
    "        return value\n",
    "\n",
    "class BehaviorCloningLoss(nn.Module):\n",
    "    \"\"\"Loss function for behavior cloning phase\"\"\"\n",
    "    def __init__(self, action_weight=1.0, unit_weight=1.0, coord_weight=1.0):\n",
    "        super(BehaviorCloningLoss, self).__init__()\n",
    "        self.action_weight = action_weight\n",
    "        self.unit_weight = unit_weight\n",
    "        self.coord_weight = coord_weight\n",
    "\n",
    "    def forward(self, outputs, target_units, target_actions, target_coords):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            outputs: Dictionary from policy network\n",
    "            target_units: Binary mask of which units should be selected [batch_size, unit_dim]\n",
    "            target_actions: Actions for selected units [num_selected_units]\n",
    "            target_coords: Coordinates for selected units [num_selected_units, 2]\n",
    "        \"\"\"\n",
    "        # Binary cross entropy for unit selection\n",
    "        unit_loss = F.binary_cross_entropy_with_logits(\n",
    "            outputs['unit_probs'], target_units.float()\n",
    "        )\n",
    "        \n",
    "        # Cross entropy loss for actions of selected units\n",
    "        selected_mask = target_units.bool()\n",
    "        action_loss = -torch.mean(\n",
    "            torch.log(outputs['action_probs'][selected_mask].gather(1, target_actions))\n",
    "        )\n",
    "        \n",
    "        # MSE loss for coordinates of selected units\n",
    "        coord_loss = F.mse_loss(\n",
    "            outputs['coordinates'][selected_mask], target_coords\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'total_loss': unit_loss + action_loss + coord_loss,\n",
    "            'unit_loss': unit_loss,\n",
    "            'action_loss': action_loss,\n",
    "            'coord_loss': coord_loss\n",
    "        }\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    batch_size = 16\n",
    "    seq_len = 100\n",
    "    input_dim = 512\n",
    "    \n",
    "    # Create networks\n",
    "    base_net = BaseNetwork()\n",
    "    policy_net = PolicyNetwork(base_net)\n",
    "    value_net = ValueNetwork(base_net)\n",
    "    \n",
    "    # Create loss function for behavior cloning\n",
    "    bc_criterion = BehaviorCloningLoss(action_weight=1.0, unit_weight=0.8, coord_weight=0.5)\n",
    "    \n",
    "    # Sample inputs\n",
    "    state = torch.randn(batch_size, seq_len, input_dim)\n",
    "    available_actions = torch.ones(batch_size, 2, dtype=torch.bool)\n",
    "    available_units = torch.ones(batch_size, 16, dtype=torch.bool)\n",
    "    \n",
    "    # Forward passes\n",
    "    policy_outputs = policy_net(state, available_actions, available_units)\n",
    "    state_values = value_net(state)\n",
    "    \n",
    "    # Create sample target data - now with multiple units per batch\n",
    "    target_units = torch.zeros(batch_size, 16, dtype=torch.bool)\n",
    "    # Randomly select 2-4 units per batch\n",
    "    for i in range(batch_size):\n",
    "        num_units = torch.randint(2, 5, (1,)).item()\n",
    "        selected_units = torch.randperm(16)[:num_units]\n",
    "        target_units[i, selected_units] = True\n",
    "    \n",
    "    # Generate actions and coordinates only for selected units\n",
    "    num_selected = target_units.sum().item()\n",
    "    target_actions = torch.randint(0, 2, (num_selected, 1))\n",
    "    target_coords = torch.randn(num_selected, 2)\n",
    "    \n",
    "    # Calculate behavior cloning loss\n",
    "    bc_loss_dict = bc_criterion(\n",
    "        policy_outputs,\n",
    "        target_units,\n",
    "        target_actions,\n",
    "        target_coords\n",
    "    )\n",
    "    \n",
    "    # Sample actions for inference\n",
    "    sampled_actions = policy_net.sample_actions(policy_outputs)\n",
    "    \n",
    "    print(f\"Parameters in base network: {count_parameters(base_net)}\")\n",
    "    print(f\"Parameters in policy network: {count_parameters(policy_net)}\")\n",
    "    print(f\"Parameters in value network: {count_parameters(value_net)}\")\n",
    "    \n",
    "    print(f\"\\nBehavior Cloning Losses:\")\n",
    "    print(f\"Total loss: {bc_loss_dict['total_loss'].item():.4f}\")\n",
    "    print(f\"Action loss: {bc_loss_dict['action_loss'].item():.4f}\")\n",
    "    print(f\"Unit loss: {bc_loss_dict['unit_loss'].item():.4f}\")\n",
    "    print(f\"Coordinate loss: {bc_loss_dict['coord_loss'].item():.4f}\")\n",
    "    \n",
    "    print(f\"\\nNetwork Outputs:\")\n",
    "    print(f\"Action probs shape: {policy_outputs['action_probs'].shape}\")\n",
    "    print(f\"Unit probs shape: {policy_outputs['unit_probs'].shape}\")\n",
    "    print(f\"Coordinates shape: {policy_outputs['coordinates'].shape}\")\n",
    "    \n",
    "    print(f\"\\nSampled Actions:\")\n",
    "    print(f\"Number of units selected: {sampled_actions['selected_units'].sum().item()}\")\n",
    "    print(f\"Actions shape: {sampled_actions['actions'].shape}\")\n",
    "    print(f\"Coordinates shape: {sampled_actions['coordinates'].shape}\")\n",
    "    \n",
    "    print(f\"\\nState values shape: {state_values.shape}\")\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(obs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters in base network: 788480\n",
      "Parameters in policy network: 1069088\n",
      "Parameters in value network: 821505\n",
      "\n",
      "Behavior Cloning Losses:\n",
      "Total loss: 2.8850\n",
      "Action loss: 0.8750\n",
      "Unit loss: 0.8671\n",
      "Coordinate loss: 1.1429\n",
      "\n",
      "Network Outputs:\n",
      "Action probs shape: torch.Size([16, 16, 2])\n",
      "Unit probs shape: torch.Size([16, 16])\n",
      "Coordinates shape: torch.Size([16, 16, 2])\n",
      "\n",
      "Sampled Actions:\n",
      "Number of units selected: 104\n",
      "Actions shape: torch.Size([104, 1])\n",
      "Coordinates shape: torch.Size([104, 2])\n",
      "\n",
      "State values shape: torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "seq_len = 500\n",
    "input_dim = 512\n",
    "\n",
    "# Create networks\n",
    "base_net = BaseNetwork()\n",
    "policy_net = PolicyNetwork(base_net)\n",
    "value_net = ValueNetwork(base_net)\n",
    "\n",
    "# Create loss function for behavior cloning\n",
    "bc_criterion = BehaviorCloningLoss(action_weight=1.0, unit_weight=0.8, coord_weight=0.5)\n",
    "\n",
    "# Sample inputs\n",
    "state = torch.randn(batch_size, seq_len, input_dim)\n",
    "available_actions = torch.ones(batch_size, 2, dtype=torch.bool)\n",
    "available_units = torch.ones(batch_size, 16, dtype=torch.bool)\n",
    "\n",
    "# Forward passes\n",
    "policy_outputs = policy_net(state, available_actions, available_units)\n",
    "state_values = value_net(state)\n",
    "\n",
    "# Create sample target data - now with multiple units per batch\n",
    "target_units = torch.zeros(batch_size, 16, dtype=torch.bool)\n",
    "# Randomly select 2-4 units per batch\n",
    "for i in range(batch_size):\n",
    "    num_units = torch.randint(2, 5, (1,)).item()\n",
    "    selected_units = torch.randperm(16)[:num_units]\n",
    "    target_units[i, selected_units] = True\n",
    "\n",
    "# Generate actions and coordinates only for selected units\n",
    "num_selected = target_units.sum().item()\n",
    "target_actions = torch.randint(0, 2, (num_selected, 1))\n",
    "target_coords = torch.randn(num_selected, 2)\n",
    "\n",
    "# Calculate behavior cloning loss\n",
    "bc_loss_dict = bc_criterion(\n",
    "    policy_outputs,\n",
    "    target_units,\n",
    "    target_actions,\n",
    "    target_coords\n",
    ")\n",
    "\n",
    "# Sample actions for inference\n",
    "sampled_actions = policy_net.sample_actions(policy_outputs)\n",
    "\n",
    "print(f\"Parameters in base network: {count_parameters(base_net)}\")\n",
    "print(f\"Parameters in policy network: {count_parameters(policy_net)}\")\n",
    "print(f\"Parameters in value network: {count_parameters(value_net)}\")\n",
    "\n",
    "print(f\"\\nBehavior Cloning Losses:\")\n",
    "print(f\"Total loss: {bc_loss_dict['total_loss'].item():.4f}\")\n",
    "print(f\"Action loss: {bc_loss_dict['action_loss'].item():.4f}\")\n",
    "print(f\"Unit loss: {bc_loss_dict['unit_loss'].item():.4f}\")\n",
    "print(f\"Coordinate loss: {bc_loss_dict['coord_loss'].item():.4f}\")\n",
    "\n",
    "print(f\"\\nNetwork Outputs:\")\n",
    "print(f\"Action probs shape: {policy_outputs['action_probs'].shape}\")\n",
    "print(f\"Unit probs shape: {policy_outputs['unit_probs'].shape}\")\n",
    "print(f\"Coordinates shape: {policy_outputs['coordinates'].shape}\")\n",
    "\n",
    "print(f\"\\nSampled Actions:\")\n",
    "print(f\"Number of units selected: {sampled_actions['selected_units'].sum().item()}\")\n",
    "print(f\"Actions shape: {sampled_actions['actions'].shape}\")\n",
    "print(f\"Coordinates shape: {sampled_actions['coordinates'].shape}\")\n",
    "\n",
    "print(f\"\\nState values shape: {state_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0152],\n",
       "        [-0.0281],\n",
       "        [ 0.0524],\n",
       "        [-0.0249],\n",
       "        [ 0.0808],\n",
       "        [ 0.0091],\n",
       "        [-0.0017],\n",
       "        [ 0.0086],\n",
       "        [ 0.0012],\n",
       "        [-0.0307],\n",
       "        [-0.0414],\n",
       "        [-0.0295],\n",
       "        [ 0.0160],\n",
       "        [-0.0524],\n",
       "        [-0.0156],\n",
       "        [ 0.0114]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_net = BaseNetwork()\n",
    "policy_net = PolicyNetwork(base_net)\n",
    "value_net = ValueNetwork(base_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbase_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[143], line 31\u001b[0m, in \u001b[0;36mBaseNetwork.forward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     29\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(state)  \u001b[38;5;66;03m# [batch_size, seq_len, lstm_hidden_size]\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(lstm_out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 31\u001b[0m lstm_final \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_out\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# [batch_size, lstm_hidden_size]\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lstm_final\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "base_net(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map_features': {'energy': tensor([[[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]]]),\n",
       "  'tile_type': tensor([[[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]]])},\n",
       " 'sensor_mask': tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]]]),\n",
       " 'units': {'position': tensor([[[[-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.]],\n",
       "  \n",
       "           [[-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.],\n",
       "            [-1., -1.]]]]),\n",
       "  'energy': tensor([[[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1.],\n",
       "           [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "            -1., -1.]]])},\n",
       " 'units_mask': tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]),\n",
       " 'relic_nodes': tensor([[[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.]]]),\n",
       " 'relic_nodes_mask': tensor([[0., 0., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 72\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mState values shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_values\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[125], line 21\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m available_units \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(batch_size, \u001b[38;5;241m16\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Forward passes\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m policy_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavailable_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavailable_units\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m state_values \u001b[38;5;241m=\u001b[39m value_net(state)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Create sample target data - now with multiple units per batch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[124], line 61\u001b[0m, in \u001b[0;36mPolicyNetwork.forward\u001b[0;34m(self, state, available_actions, available_units)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, state, available_actions, available_units):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m        state: Input state tensor (batch_size, seq_len, input_dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m        Dictionary containing action distributions for each unit\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     lstm_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Target unit selection - now returns probabilities for EACH unit\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     unit_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_embedding(torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_dim)\u001b[38;5;241m.\u001b[39mto(state\u001b[38;5;241m.\u001b[39mdevice))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[124], line 28\u001b[0m, in \u001b[0;36mBaseNetwork.forward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs):\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    Process state through LSTM\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m        lstm_final: Final LSTM hidden state (batch_size, lstm_hidden_size)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(state)  \u001b[38;5;66;03m# [batch_size, seq_len, lstm_hidden_size]\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     lstm_final \u001b[38;5;241m=\u001b[39m lstm_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# [batch_size, lstm_hidden_size]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[116], line 77\u001b[0m, in \u001b[0;36mLuxAIObservationEncoder.forward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# Process spatial features\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     spatial_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[0;32m---> 77\u001b[0m         \u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmap_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     78\u001b[0m         obs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap_features\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtile_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     79\u001b[0m         obs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msensor_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     80\u001b[0m     ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     81\u001b[0m     spatial_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial_encoder(spatial_features)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# Process units\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 3"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    batch_size = 16\n",
    "    seq_len = 100\n",
    "    input_dim = 64\n",
    "    \n",
    "    # Create networks\n",
    "    base_net = BaseNetwork()\n",
    "    policy_net = PolicyNetwork(base_net)\n",
    "    value_net = ValueNetwork(base_net)\n",
    "    \n",
    "    # Create loss function for behavior cloning\n",
    "    bc_criterion = BehaviorCloningLoss(action_weight=1.0, unit_weight=0.8, coord_weight=0.5)\n",
    "    \n",
    "    # Sample inputs\n",
    "    state = torch.randn(batch_size, seq_len, input_dim)\n",
    "    available_actions = torch.ones(batch_size, 2, dtype=torch.bool)\n",
    "    available_units = torch.ones(batch_size, 16, dtype=torch.bool)\n",
    "    \n",
    "    # Forward passes\n",
    "    policy_outputs = policy_net(state, available_actions, available_units)\n",
    "    state_values = value_net(state)\n",
    "    \n",
    "    # Create sample target data - now with multiple units per batch\n",
    "    target_units = torch.zeros(batch_size, 16, dtype=torch.bool)\n",
    "    # Randomly select 2-4 units per batch\n",
    "    for i in range(batch_size):\n",
    "        num_units = torch.randint(2, 5, (1,)).item()\n",
    "        selected_units = torch.randperm(16)[:num_units]\n",
    "        target_units[i, selected_units] = True\n",
    "    \n",
    "    # Generate actions and coordinates only for selected units\n",
    "    num_selected = target_units.sum().item()\n",
    "    target_actions = torch.randint(0, 2, (num_selected, 1))\n",
    "    target_coords = torch.randn(num_selected, 2)\n",
    "    \n",
    "    # Calculate behavior cloning loss\n",
    "    bc_loss_dict = bc_criterion(\n",
    "        policy_outputs,\n",
    "        target_units,\n",
    "        target_actions,\n",
    "        target_coords\n",
    "    )\n",
    "    \n",
    "    # Sample actions for inference\n",
    "    sampled_actions = policy_net.sample_actions(policy_outputs)\n",
    "    \n",
    "    print(f\"Parameters in base network: {count_parameters(base_net)}\")\n",
    "    print(f\"Parameters in policy network: {count_parameters(policy_net)}\")\n",
    "    print(f\"Parameters in value network: {count_parameters(value_net)}\")\n",
    "    \n",
    "    print(f\"\\nBehavior Cloning Losses:\")\n",
    "    print(f\"Total loss: {bc_loss_dict['total_loss'].item():.4f}\")\n",
    "    print(f\"Action loss: {bc_loss_dict['action_loss'].item():.4f}\")\n",
    "    print(f\"Unit loss: {bc_loss_dict['unit_loss'].item():.4f}\")\n",
    "    print(f\"Coordinate loss: {bc_loss_dict['coord_loss'].item():.4f}\")\n",
    "    \n",
    "    print(f\"\\nNetwork Outputs:\")\n",
    "    print(f\"Action probs shape: {policy_outputs['action_probs'].shape}\")\n",
    "    print(f\"Unit probs shape: {policy_outputs['unit_probs'].shape}\")\n",
    "    print(f\"Coordinates shape: {policy_outputs['coordinates'].shape}\")\n",
    "    \n",
    "    print(f\"\\nSampled Actions:\")\n",
    "    print(f\"Number of units selected: {sampled_actions['selected_units'].sum().item()}\")\n",
    "    print(f\"Actions shape: {sampled_actions['actions'].shape}\")\n",
    "    print(f\"Coordinates shape: {sampled_actions['coordinates'].shape}\")\n",
    "    \n",
    "    print(f\"\\nState values shape: {state_values.shape}\")\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_outputs[\"coordinates\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_outputs[\"action_probs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_outputs[\"coordinates\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network_to_env_actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnetwork_to_env_actions\u001b[49m(policy_outputs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'network_to_env_actions' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample inputs\n",
    "state = torch.randn(batch_size, seq_len, input_dim)\n",
    "available_actions = torch.ones(batch_size, 2, dtype=torch.bool)\n",
    "available_units = torch.ones(batch_size, 16, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
